{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from vq_vae_2.examples.hierarchical.data import load_images, load_tiled_images, SwipeCropper\n",
    "from vq_vae_2.examples.hierarchical.model import make_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./results/hierarchical', exist_ok=True)\n",
    "os.makedirs('./saved_states/hierarchical', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sets = {\n",
    "    'celebA256': {\n",
    "        'VAE_PATH': './saved_states/hierarchical/celebA256/celebA256_vae_{}.pt',\n",
    "        'DATA_TRAIN': './data/celebA/data256x256/train',\n",
    "        'RESULTS': './results/hierarchical/celebA256/celebA_{}.png',\n",
    "    },\n",
    "    'celebA256_tiled': {\n",
    "        'VAE_PATH': './saved_states/hierarchical/celebA256_tiled/vae_{}.pt',\n",
    "        'DATA_TRAIN': './data/celebA/data512x512/train',\n",
    "        'RESULTS': './results/hierarchical/celebA_tiled/reconstructed_{}.png',\n",
    "    }\n",
    "}\n",
    "NAME = 'celebA256_tiled'\n",
    "LOAD_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE_PATH = training_sets[NAME]['VAE_PATH']\n",
    "DATA_TRAIN = training_sets[NAME]['DATA_TRAIN']\n",
    "RESULTS = training_sets[NAME]['RESULTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(VAE_PATH.format(0)), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(RESULTS.format(0)), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a hierarchical VQ-VAE on 256x256 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reconstructions(vae, images, RESULTS, i):\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        recons = [torch.clamp(x, 0, 1).permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "                  for x in vae.full_reconstructions(images)]\n",
    "    vae.train()\n",
    "    top_recons, real_recons = recons\n",
    "    images = images.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "\n",
    "    columns = np.concatenate([top_recons, real_recons, images], axis=-2)\n",
    "    columns = np.concatenate(columns, axis=0)\n",
    "    Image.fromarray((columns * 255).astype('uint8')).save(\n",
    "        RESULTS.format(i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = make_vae()\n",
    "if os.path.exists(VAE_PATH.format(LOAD_EPOCH)):\n",
    "    model.load_state_dict(torch.load(VAE_PATH.format(LOAD_EPOCH), map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# data = load_images(DATA_TRAIN)\n",
    "data = load_tiled_images(DATA_TRAIN, width=256, height=256)\n",
    "for i in itertools.count():\n",
    "    batch = next(data)\n",
    "    images = batch.to(DEVICE)\n",
    "    terms = model(images)\n",
    "    print('step %d: mse=%f mse_top=%f' %\n",
    "          (i, terms['losses'][-1].item(), terms['losses'][0].item()))\n",
    "    optimizer.zero_grad()\n",
    "    terms['loss'].backward()\n",
    "    optimizer.step()\n",
    "    model.revive_dead_entries()\n",
    "    if not i % 30:\n",
    "        torch.save(model.state_dict(), VAE_PATH.format(i))\n",
    "        save_reconstructions(model, images, RESULTS, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
